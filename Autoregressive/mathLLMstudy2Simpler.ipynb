{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pprint\n",
    "import math\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Torch Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self,\n",
    "                 emb_size: int,\n",
    "                 dropout: float,\n",
    "                 maxlen: int = 512):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        den = torch.exp(- torch.arange(0, emb_size, 2)* math.log(10000) / emb_size)\n",
    "        pos = torch.arange(0, maxlen).reshape(maxlen, 1)\n",
    "        pos_embedding = torch.zeros((maxlen, emb_size))\n",
    "        pos_embedding[:, 0::2] = torch.sin(pos * den)\n",
    "        pos_embedding[:, 1::2] = torch.cos(pos * den)\n",
    "        pos_embedding = pos_embedding.unsqueeze(-2)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.register_buffer('pos_embedding', pos_embedding)\n",
    "\n",
    "    def forward(self, token_embedding: torch.Tensor):\n",
    "        return self.dropout(token_embedding + self.pos_embedding[:token_embedding.size(0), :])\n",
    "\n",
    "class TokenEmbedding(nn.Module):\n",
    "    def __init__(self, vocab_size: int, emb_size):\n",
    "        super(TokenEmbedding, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, emb_size).to(device)\n",
    "        self.emb_size = emb_size\n",
    "\n",
    "    def forward(self, tokens: torch.Tensor):\n",
    "        return self.embedding(tokens.long()) * math.sqrt(self.emb_size)\n",
    "\n",
    "class Autoregressive(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_size, hidden_size, num_layers):\n",
    "        super(Autoregressive, self).__init__()\n",
    "\n",
    "        # Embedding layer\n",
    "        self.embedding = TokenEmbedding(vocab_size, embed_size).to(device)\n",
    "        # positional Encoding\n",
    "        self.positional_encoding = PositionalEncoding(embed_size, dropout=0.1).to(device)\n",
    "        # Transformer blocks\n",
    "        self.transformer_blocks = nn.ModuleList([\n",
    "            nn.TransformerEncoderLayer(d_model=hidden_size, nhead=4, dropout=0.1)\n",
    "            for _ in range(num_layers)\n",
    "        ])\n",
    "\n",
    "        # Fully connected layer for prediction\n",
    "        self.fc = nn.Linear(hidden_size, vocab_size)\n",
    "\n",
    "    def forward(self, input_seq):\n",
    "        # Embedding input sequence\n",
    "        embedded_seq = self.embedding(input_seq)\n",
    "        embedded_seq = self.positional_encoding(embedded_seq)\n",
    "        # Transformer blocks\n",
    "        for transformer_block in self.transformer_blocks:\n",
    "            embedded_seq = transformer_block(embedded_seq)\n",
    "\n",
    "        # Prediction\n",
    "        output = self.fc(embedded_seq[-1, :, :])\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='mps')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('mps' if torch.backends.mps.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################################\n",
    "# Let's now define the parameters of our model and instantiate the same. Below, we also\n",
    "# define our loss function which is the cross-entropy loss and the optimizer used for training.\n",
    "#\n",
    "torch.manual_seed(0)\n",
    "\n",
    "VOCAB_SIZE = 151#vocab.num_words+1\n",
    "EMB_SIZE = 512\n",
    "NHEAD = 8\n",
    "FFN_HID_DIM = 512\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "model = Autoregressive(VOCAB_SIZE, EMB_SIZE, FFN_HID_DIM, NHEAD)\n",
    "\n",
    "for p in model.parameters():\n",
    "    if p.dim() > 1:\n",
    "        nn.init.xavier_uniform_(p)\n",
    "\n",
    "model = model.to(device)\n",
    "criterion = torch.nn.CrossEntropyLoss(ignore_index=0)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001, betas=(0.9, 0.98), eps=1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 25,373,847 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "        return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "def save_to_file(objeto, nome_arquivo):\n",
    "    with open(nome_arquivo, 'wb') as output:\n",
    "        pickle.dump(objeto, output, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "\n",
    "def load_file(nome_arquivo):\n",
    "    with open(nome_arquivo, 'rb') as input:\n",
    "        objeto = pickle.load(input)\n",
    "    return objeto\n",
    "\n",
    "def chunks(lst, n):\n",
    "    \"\"\"Yield successive n-sized chunks from lst.\"\"\"\n",
    "    for i in range(0, len(lst), n):\n",
    "            yield lst[i:i + n]\n",
    "\n",
    "sub_path = './'\n",
    "\n",
    "vocab = load_file(sub_path+'vocab.pkl')\n",
    "\n",
    "src = load_file(sub_path+'srcSimpler.pkl')\n",
    "trg = load_file(sub_path+'trgSimpler.pkl')\n",
    "\n",
    "srcVal = load_file(sub_path+'srcValSimpler.pkl')\n",
    "trgVal = load_file(sub_path+'trgValSimpler.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([60, 1480806]),\n",
       " torch.Size([1480806]),\n",
       " torch.Size([60, 370017]),\n",
       " torch.Size([370017]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src.shape, trg.shape, srcVal.shape, trgVal.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "BATCHSIZE = 128\n",
    "\n",
    "def chunks(lst, n):\n",
    "    \"\"\"Yield successive n-sized chunks from lst.\"\"\"\n",
    "    for i in range(0, len(lst), n):\n",
    "            yield lst[i:i + n]\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs\n",
    "\n",
    "def train(model, optimizer, criterion, src, trg):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    it = 0\n",
    "    for i in chunks(np.arange(src.shape[1]), BATCHSIZE):\n",
    "        it += 1\n",
    "        output = model(\n",
    "            src[:,i].to(device)\n",
    "        )\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(output.view(-1, output.shape[-1]), trg[i].to(device).view(-1))\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1)\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "    return epoch_loss / BATCHSIZE\n",
    "\n",
    "def evaluate(model, criterion, src, trg):\n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for i in chunks(np.arange(src.shape[1]), BATCHSIZE):\n",
    "            output = model(\n",
    "                src[:,i].to(device)\n",
    "            )\n",
    "            loss = criterion(output.view(-1, output.shape[-1]), trg[i].to(device).view(-1))\n",
    "            epoch_loss += loss.item()\n",
    "            gc.collect()\n",
    "            torch.cuda.empty_cache()\n",
    "    return epoch_loss / BATCHSIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode(model, src, maxlen=30):\n",
    "    response = []\n",
    "    with torch.no_grad():\n",
    "        while True:\n",
    "            output = model(src.to(device))\n",
    "            word = output.squeeze().argmax()\n",
    "            response.append(int(word.cpu().numpy()))\n",
    "            src = torch.cat((srcVal[:,rnd-1:rnd].cpu(),torch.tensor([[int(word.cpu().numpy())]])),dim=0)\n",
    "            if word == 2 or len(response) == maxlen:\n",
    "                break\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "succeeding standpoint 4 4 4 make 4 make make make make 4 understand standpoint 3 4 understand 4 understand 4 understand 4 4 4 <num> 4 4 make standpoint standpoint 3 standpoint make 4 4 standpoint make 3 make 4 understand standpoint standpoint standpoint make standpoint could 4 standpoint impression make standpoint 4 4 4 understand impression 4 4 3\n"
     ]
    }
   ],
   "source": [
    "rnd = np.random.randint(1,100)\n",
    "o = decode(model, srcVal[:,rnd-1:rnd].to(device),60)\n",
    "print(' '.join( vocab.index2word[i] for i in o))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Loaded Successfully!\n",
      "Start training 0\n",
      "Validating... 0\n",
      "Epoch: 01 | Time: 77m 35s\n",
      "\tTrain Loss: 30.172 | Train PPL: 12696148251230.764\n",
      "\t Val. Loss: 34.744 |    Val. PPL: 1228270249703555.000\n",
      "Testing:\n",
      "\n",
      "\t Query:\n",
      "\tPAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD SOS can you solve this subsequent mathematical function :  ( <num> 7 </num> + <num> 5 </num> ) EOS SOS it strikes me as possible that the response is :  <num> 1 2\n",
      "\n",
      "\t Answer:\n",
      "\t</num> EOS\n",
      "\n",
      "\n",
      "\n",
      "Start training 1\n",
      "Validating... 1\n",
      "Epoch: 02 | Time: 79m 9s\n",
      "\tTrain Loss: 30.226 | Train PPL: 13392793701646.754\n",
      "\t Val. Loss: 34.009 |    Val. PPL: 588957441234806.625\n",
      "Start training 2\n",
      "Validating... 2\n",
      "Epoch: 03 | Time: 81m 53s\n",
      "\tTrain Loss: 30.826 | Train PPL: 24399221451482.246\n",
      "\t Val. Loss: 63.522 |    Val. PPL: 3864388997450516340701921280.000\n",
      "Start training 3\n",
      "Validating... 3\n",
      "Epoch: 04 | Time: 80m 0s\n",
      "\tTrain Loss: 31.221 | Train PPL: 36250466100053.133\n",
      "\t Val. Loss: 60.211 |    Val. PPL: 141039426508387122084315136.000\n",
      "Start training 4\n",
      "Validating... 4\n",
      "Epoch: 05 | Time: 81m 6s\n",
      "\tTrain Loss: 31.662 | Train PPL: 56316545497473.172\n",
      "\t Val. Loss: 50.024 |    Val. PPL: 5313136395573377630208.000\n",
      "Start training 5\n",
      "Validating... 5\n",
      "Epoch: 06 | Time: 81m 31s\n",
      "\tTrain Loss: 32.157 | Train PPL: 92342160891502.359\n",
      "\t Val. Loss: 40.709 |    Val. PPL: 478318182623995584.000\n",
      "Start training 6\n",
      "Validating... 6\n",
      "Epoch: 07 | Time: 80m 41s\n",
      "\tTrain Loss: 31.743 | Train PPL: 61037579671273.758\n",
      "\t Val. Loss: 38.085 |    Val. PPL: 34679764750380032.000\n",
      "Start training 7\n",
      "Validating... 7\n",
      "Epoch: 08 | Time: 495m 17s\n",
      "\tTrain Loss: 32.866 | Train PPL: 187716918151975.438\n",
      "\t Val. Loss: 32.540 |    Val. PPL: 135448437129564.500\n",
      "Start training 8\n",
      "Validating... 8\n",
      "Epoch: 09 | Time: 288m 8s\n",
      "\tTrain Loss: 33.262 | Train PPL: 278836316788401.031\n",
      "\t Val. Loss: 33.197 |    Val. PPL: 261444742797584.781\n",
      "Start training 9\n",
      "Validating... 9\n",
      "Epoch: 10 | Time: 82m 4s\n",
      "\tTrain Loss: 33.506 | Train PPL: 355914125511254.125\n",
      "\t Val. Loss: 72.480 |    Val. PPL: 30036779881560540942067033964544.000\n",
      "Start training 10\n",
      "Validating... 10\n",
      "Epoch: 11 | Time: 83m 16s\n",
      "\tTrain Loss: 34.075 | Train PPL: 629040072336516.250\n",
      "\t Val. Loss: 44.810 |    Val. PPL: 28878673096682766336.000\n",
      "Testing:\n",
      "\n",
      "\t Query:\n",
      "\tPAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD SOS hey ,  would you calculate the subsequent formula :  <num> 3 </num> + <num> 2 </num> EOS SOS\n",
      "\n",
      "\t Answer:\n",
      "\t<num> 5 </num> EOS\n",
      "\n",
      "\n",
      "\n",
      "Start training 11\n",
      "Validating... 11\n",
      "Epoch: 12 | Time: 83m 50s\n",
      "\tTrain Loss: 33.662 | Train PPL: 415971062824650.188\n",
      "\t Val. Loss: 49.018 |    Val. PPL: 1941550640344109678592.000\n",
      "Start training 12\n",
      "Validating... 12\n",
      "Epoch: 13 | Time: 87m 2s\n",
      "\tTrain Loss: 33.648 | Train PPL: 410167397080081.188\n",
      "\t Val. Loss: 52.359 |    Val. PPL: 54833353538467098787840.000\n",
      "Start training 13\n",
      "Validating... 13\n",
      "Epoch: 14 | Time: 86m 55s\n",
      "\tTrain Loss: 34.443 | Train PPL: 908627280620166.750\n",
      "\t Val. Loss: 52.082 |    Val. PPL: 41580518605405271621632.000\n",
      "Start training 14\n",
      "Validating... 14\n",
      "Epoch: 15 | Time: 87m 51s\n",
      "\tTrain Loss: 34.905 | Train PPL: 1441978385866249.750\n",
      "\t Val. Loss: 51.852 |    Val. PPL: 33052697132174193721344.000\n",
      "Start training 15\n",
      "Validating... 15\n",
      "Epoch: 16 | Time: 80m 25s\n",
      "\tTrain Loss: 34.664 | Train PPL: 1132950338729782.500\n",
      "\t Val. Loss: 55.987 |    Val. PPL: 2064457253091850498080768.000\n",
      "Start training 16\n",
      "Validating... 16\n",
      "Epoch: 17 | Time: 86m 1s\n",
      "\tTrain Loss: 35.464 | Train PPL: 2522079256162210.000\n",
      "\t Val. Loss: 72.312 |    Val. PPL: 25393409013094371993326320615424.000\n",
      "Start training 17\n",
      "Validating... 17\n",
      "Epoch: 18 | Time: 83m 6s\n",
      "\tTrain Loss: 36.003 | Train PPL: 4325547031614765.000\n",
      "\t Val. Loss: 46.805 |    Val. PPL: 212486565353291874304.000\n",
      "Start training 18\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 1000\n",
    "CLIP = 1\n",
    "path = './'\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "try: \n",
    "    model.load_state_dict(torch.load(path+'math-bert-model.pt'))\n",
    "    print('Model Loaded Successfully!')\n",
    "except:\n",
    "    print('No model loaded, starting training from scratch.')\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    start_time = time.time()\n",
    "    print('Start training',epoch)\n",
    "    train_loss = train(model, optimizer, criterion, src, trg)\n",
    "    print('Validating...',epoch)\n",
    "    valid_loss = evaluate(model, criterion, srcVal, trgVal)\n",
    "\n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), path+'math-bert-model.pt')\n",
    "\n",
    "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |    Val. PPL: {math.exp(valid_loss):7.3f}')\n",
    "    with open(path+\"modelTrainingOutput.txt\", \"a\") as textFile:\n",
    "        textFile.write(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s\\n')\n",
    "        textFile.write(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}\\n')\n",
    "        textFile.write(f'\\t Val. Loss: {valid_loss:.3f} |    Val. PPL: {math.exp(valid_loss):7.3f}\\n')\n",
    "    if epoch % 10 == 0:\n",
    "        with torch.no_grad():\n",
    "            rnd = np.random.randint(1,100)\n",
    "            o = decode(model, srcVal[:,rnd-1:rnd].to(device),60)\n",
    "            query = ' '.join( vocab.index2word[i] for i in srcVal[:,rnd-1:rnd].squeeze().cpu().numpy())\n",
    "            answer = ' '.join( vocab.index2word[i] for i in o)\n",
    "        print(f'Testing:\\n')\n",
    "        print(f'\\t Query:\\n\\t'+query+'\\n')\n",
    "        print(f'\\t Answer:\\n\\t'+answer+'\\n')\n",
    "        print(f'\\n')\n",
    "        with open(path+\"modelTrainingOutputSimpler.txt\", \"a\") as textFile:\n",
    "            textFile.write(f'Testing:\\n')\n",
    "            textFile.write(f'\\t Query:\\n\\t'+query+'\\n')\n",
    "            textFile.write(f'\\t Answer:\\n\\t'+answer+'\\n')\n",
    "            textFile.write(f'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
