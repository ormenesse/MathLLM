{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vormenesse\\anaconda3\\lib\\site-packages\\spacy\\util.py:910: UserWarning: [W095] Model 'de_core_news_sm' (3.3.0) was trained with spaCy v3.3.0 and may not be 100% compatible with the current version (3.7.2). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
      "  warnings.warn(warn_msg)\n",
      "c:\\Users\\vormenesse\\anaconda3\\lib\\site-packages\\spacy\\util.py:910: UserWarning: [W095] Model 'en_core_web_sm' (3.3.0) was trained with spaCy v3.3.0 and may not be 100% compatible with the current version (3.7.2). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
      "  warnings.warn(warn_msg)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import spacy\n",
    "import numpy as np\n",
    "\n",
    "import random\n",
    "import math\n",
    "import time\n",
    "\n",
    "from functions import *\n",
    "\n",
    "spacy_de = spacy.load('de_core_news_sm')\n",
    "spacy_en = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('train.en') as f:\n",
    "    trainEn = f.readlines()\n",
    "with open('train.de') as f:\n",
    "    trainDe = f.readlines()\n",
    "with open('val.en') as f:\n",
    "    valEn = f.readlines()\n",
    "with open('val.de') as f:\n",
    "    valDe = f.readlines()\n",
    "\n",
    "engVocabulary = Vocabulary('en',spacy_en,40)\n",
    "deVocabulary = Vocabulary('de',spacy_de,40)\n",
    "\n",
    "for i in trainEn:\n",
    "  engVocabulary.add_sentence(i)\n",
    "for i in trainDe:\n",
    "  deVocabulary.add_sentence(i)\n",
    "for i in valEn:\n",
    "  engVocabulary.add_sentence(i)\n",
    "for i in valDe:\n",
    "  deVocabulary.add_sentence(i)\n",
    "\n",
    "src = []\n",
    "for j in np.array(trainEn):\n",
    "    src.append(engVocabulary.sentence_to_index(j,padding=True))\n",
    "src = torch.tensor(src,dtype=torch.long, device=device)\n",
    "trg = []\n",
    "for j in np.array(trainDe):\n",
    "    trg.append(deVocabulary.sentence_to_index(j,padding=True))\n",
    "trg = torch.tensor(trg,dtype=torch.long, device=device)\n",
    "trg = trg.T\n",
    "src = src.T\n",
    "\n",
    "valsrc = []\n",
    "for j in np.array(valEn):\n",
    "    valsrc.append(engVocabulary.sentence_to_index(j,padding=True))\n",
    "valsrc = torch.tensor(valsrc,dtype=torch.long, device=device)\n",
    "valtrg = []\n",
    "for j in np.array(valDe):\n",
    "    valtrg.append(deVocabulary.sentence_to_index(j,padding=True))\n",
    "valtrg = torch.tensor(valtrg,dtype=torch.long, device=device)\n",
    "valtrg = valtrg.T\n",
    "valsrc = valsrc.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9951, 19062)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "engVocabulary.num_words,deVocabulary.num_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################################\n",
    "# Seq2Seq Network using Transformer\n",
    "# ---------------------------------\n",
    "#\n",
    "# Transformer is a Seq2Seq model introduced in `“Attention is all you\n",
    "# need” <https://papers.nips.cc/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf>`__\n",
    "# paper for solving machine translation tasks.\n",
    "# Below, we will create a Seq2Seq network that uses Transformer. The network\n",
    "# consists of three parts. First part is the embedding layer. This layer converts tensor of input indices\n",
    "# into corresponding tensor of input embeddings. These embedding are further augmented with positional\n",
    "# encodings to provide position information of input tokens to the model. The second part is the\n",
    "# actual `Transformer <https://pytorch.org/docs/stable/generated/torch.nn.Transformer.html>`__ model.\n",
    "# Finally, the output of the Transformer model is passed through linear layer\n",
    "# that gives unnormalized probabilities for each token in the target language.\n",
    "#\n",
    "\n",
    "\n",
    "from torch import Tensor\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import Transformer\n",
    "import math\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# Define special symbols and indices\n",
    "UNK_IDX, PAD_IDX, BOS_IDX, EOS_IDX = -1, 0, 1, 2\n",
    "\n",
    "# helper Module that adds positional encoding to the token embedding to introduce a notion of word order.\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self,\n",
    "                 emb_size: int,\n",
    "                 dropout: float,\n",
    "                 maxlen: int = 5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        den = torch.exp(- torch.arange(0, emb_size, 2)* math.log(10000) / emb_size)\n",
    "        pos = torch.arange(0, maxlen).reshape(maxlen, 1)\n",
    "        pos_embedding = torch.zeros((maxlen, emb_size))\n",
    "        pos_embedding[:, 0::2] = torch.sin(pos * den)\n",
    "        pos_embedding[:, 1::2] = torch.cos(pos * den)\n",
    "        pos_embedding = pos_embedding.unsqueeze(-2)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.register_buffer('pos_embedding', pos_embedding)\n",
    "\n",
    "    def forward(self, token_embedding: Tensor):\n",
    "        return self.dropout(token_embedding + self.pos_embedding[:token_embedding.size(0), :])\n",
    "\n",
    "# helper Module to convert tensor of input indices into corresponding tensor of token embeddings\n",
    "class TokenEmbedding(nn.Module):\n",
    "    def __init__(self, vocab_size: int, emb_size):\n",
    "        super(TokenEmbedding, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, emb_size)\n",
    "        self.emb_size = emb_size\n",
    "\n",
    "    def forward(self, tokens: Tensor):\n",
    "        return self.embedding(tokens.long()) * math.sqrt(self.emb_size)\n",
    "\n",
    "# Seq2Seq Network\n",
    "class Seq2SeqTransformer(nn.Module):\n",
    "    def __init__(self,\n",
    "                 num_encoder_layers: int,\n",
    "                 num_decoder_layers: int,\n",
    "                 emb_size: int,\n",
    "                 nhead: int,\n",
    "                 src_vocab_size: int,\n",
    "                 tgt_vocab_size: int,\n",
    "                 dim_feedforward: int = 512,\n",
    "                 dropout: float = 0.1):\n",
    "        super(Seq2SeqTransformer, self).__init__()\n",
    "        self.transformer = Transformer(d_model=emb_size,\n",
    "                                       nhead=nhead,\n",
    "                                       num_encoder_layers=num_encoder_layers,\n",
    "                                       num_decoder_layers=num_decoder_layers,\n",
    "                                       dim_feedforward=dim_feedforward,\n",
    "                                       dropout=dropout)\n",
    "        self.generator = nn.Linear(emb_size, tgt_vocab_size)\n",
    "        self.src_tok_emb = TokenEmbedding(src_vocab_size, emb_size)\n",
    "        self.tgt_tok_emb = TokenEmbedding(tgt_vocab_size, emb_size)\n",
    "        self.positional_encoding = PositionalEncoding(\n",
    "            emb_size, dropout=dropout)\n",
    "\n",
    "    def forward(self,\n",
    "                src: Tensor,\n",
    "                trg: Tensor,\n",
    "                src_mask: Tensor,\n",
    "                tgt_mask: Tensor,\n",
    "                src_padding_mask: Tensor,\n",
    "                tgt_padding_mask: Tensor,\n",
    "                memory_key_padding_mask: Tensor):\n",
    "        src_emb = self.positional_encoding(self.src_tok_emb(src))\n",
    "        tgt_emb = self.positional_encoding(self.tgt_tok_emb(trg))\n",
    "        outs = self.transformer(src_emb, tgt_emb, src_mask, tgt_mask, None,\n",
    "                                src_padding_mask, tgt_padding_mask, memory_key_padding_mask)\n",
    "        return self.generator(outs)\n",
    "\n",
    "    def encode(self, src: Tensor, src_mask: Tensor):\n",
    "        return self.transformer.encoder(self.positional_encoding(\n",
    "                            self.src_tok_emb(src)), src_mask)\n",
    "\n",
    "    def decode(self, tgt: Tensor, memory: Tensor, tgt_mask: Tensor):\n",
    "        return self.transformer.decoder(self.positional_encoding(\n",
    "                          self.tgt_tok_emb(tgt)), memory,\n",
    "                          tgt_mask)\n",
    "\n",
    "\n",
    "######################################################################\n",
    "# During training, we need a subsequent word mask that will prevent the model from looking into\n",
    "# the future words when making predictions. We will also need masks to hide\n",
    "# source and target padding tokens. Below, let's define a function that will take care of both.\n",
    "#\n",
    "\n",
    "def generate_square_subsequent_mask(sz):\n",
    "    mask = (torch.triu(torch.ones((sz, sz), device=DEVICE)) == 1).transpose(0, 1)\n",
    "    mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "    return mask\n",
    "\n",
    "def create_mask(src, tgt):\n",
    "    src_seq_len = src.shape[0]\n",
    "    tgt_seq_len = tgt.shape[0]\n",
    "\n",
    "    tgt_mask = generate_square_subsequent_mask(tgt_seq_len)\n",
    "    src_mask = torch.zeros((src_seq_len, src_seq_len),device=DEVICE).type(torch.bool)\n",
    "\n",
    "    src_padding_mask = (src == PAD_IDX).transpose(0, 1)\n",
    "    tgt_padding_mask = (tgt == PAD_IDX).transpose(0, 1)\n",
    "    return src_mask, tgt_mask, src_padding_mask, tgt_padding_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9951, 19062)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "engVocabulary.num_words,deVocabulary.num_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################################\n",
    "# Let's now define the parameters of our model and instantiate the same. Below, we also\n",
    "# define our loss function which is the cross-entropy loss and the optimizer used for training.\n",
    "#\n",
    "torch.manual_seed(0)\n",
    "\n",
    "SRC_VOCAB_SIZE = engVocabulary.num_words+1\n",
    "TGT_VOCAB_SIZE = deVocabulary.num_words+1\n",
    "EMB_SIZE = 512\n",
    "NHEAD = 8\n",
    "FFN_HID_DIM = 512\n",
    "BATCH_SIZE = 128\n",
    "NUM_ENCODER_LAYERS = 3\n",
    "NUM_DECODER_LAYERS = 3\n",
    "\n",
    "transformer = Seq2SeqTransformer(NUM_ENCODER_LAYERS, NUM_DECODER_LAYERS, EMB_SIZE,\n",
    "                                 NHEAD, SRC_VOCAB_SIZE, TGT_VOCAB_SIZE, FFN_HID_DIM)\n",
    "\n",
    "for p in transformer.parameters():\n",
    "    if p.dim() > 1:\n",
    "        nn.init.xavier_uniform_(p)\n",
    "\n",
    "transformer = transformer.to(DEVICE)\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss(ignore_index=PAD_IDX)\n",
    "\n",
    "optimizer = torch.optim.Adam(transformer.parameters(), lr=0.0001, betas=(0.9, 0.98), eps=1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 37,259,895 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "        return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(transformer):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy_decode(model, src, max_len, start_symbol=1):\n",
    "    #print(src.shape)\n",
    "    src = (src.to(device).reshape(max_len,1))\n",
    "    #print(src.shape)\n",
    "    num_tokens = len(src)\n",
    "    src_mask = (torch.zeros(num_tokens, num_tokens)).type(torch.bool).to(device)\n",
    "    memory = model.encode(src, src_mask).to(device)\n",
    "    ys = torch.ones(1, 1).fill_(start_symbol).type(torch.long).to(device)\n",
    "    for i in range(max_len-1):\n",
    "        memory_mask = torch.zeros(ys.shape[0], memory.shape[0]).to(device).type(torch.bool)\n",
    "        tgt_mask = (generate_square_subsequent_mask(ys.size(0))\n",
    "                                    .type(torch.bool)).to(device)\n",
    "        out = model.decode(ys, memory, tgt_mask)\n",
    "        out = out.transpose(0, 1)\n",
    "        prob = model.generator(out[:, -1])\n",
    "        _, next_word = torch.max(prob, dim = 1)\n",
    "        next_word = next_word.item()\n",
    "        ys = torch.cat([ys, torch.ones(1, 1).type_as(src.data).fill_(next_word)], dim=0)\n",
    "        if next_word == 2: # 2 == EOS\n",
    "          break\n",
    "    return ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([29000]), torch.Size([40, 29000]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src[2,:].shape, src.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SOS besteckschublade plüschhaie cape farbenfrohem weiteren weiteren chinesische neuestes beleuchtetes ordentlich bauzäunen übergang side-baseballteams neuestes abgestorbenem rennenden rennenden weiteren weiteren geernteten spieß tee-ball entspannter side-baseballteams rennenden rennenden tropfen rennenden rennenden originellen rennenden rennenden rennenden spieß auffegen zaubererumhang rennenden rennenden präparat'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "asw = greedy_decode(model, src[:,2].to(device), 40, 1)\n",
    "' '.join( deVocabulary.index2word[i] for i in asw.squeeze().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "BATCHSIZE = 64\n",
    "\n",
    "def chunks(lst, n):\n",
    "    \"\"\"Yield successive n-sized chunks from lst.\"\"\"\n",
    "    for i in range(0, len(lst), n):\n",
    "            yield lst[i:i + n]\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs\n",
    "\n",
    "def train_bert(model, optimizer, criterion, src, trg):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    it = 0\n",
    "    for i in chunks(np.arange(src.shape[1]), BATCHSIZE):\n",
    "        it += 1\n",
    "        src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(src[:,i].to(device), trg[:-1,i].to(device))\n",
    "        output = model(\n",
    "            src[:,i].to(device), trg[:-1,i].to(device), src_mask,\n",
    "            tgt_mask, src_padding_mask, tgt_padding_mask, src_padding_mask\n",
    "        )\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(output.view(-1, output.shape[-1]), trg[1:,i].to(device).view(-1))\n",
    "        loss.backward()\n",
    "        #torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "    return epoch_loss / BATCHSIZE\n",
    "\n",
    "def evaluate_bert(model, criterion, src, trg):\n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for i in chunks(np.arange(src.shape[0]), BATCHSIZE):\n",
    "            src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(src[:,i].to(device), trg[:-1,i].to(device))\n",
    "            output = model(\n",
    "                src[:,i].to(device), trg[:-1,i].to(device), src_mask,\n",
    "                tgt_mask, src_padding_mask, tgt_padding_mask, src_padding_mask\n",
    "            )\n",
    "            #loss = criterion(output.argmax(2).reshape(-1,1)[:,0], trg[i,:].to(device).reshape(-1,1)[:,0])\n",
    "            loss = criterion(output.view(-1, output.shape[-1]), trg[1:,i].to(device).view(-1))\n",
    "            epoch_loss += loss.item()\n",
    "            gc.collect()\n",
    "            torch.cuda.empty_cache()\n",
    "    return epoch_loss / BATCHSIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in chunks(np.arange(src.shape[1]), BATCHSIZE):\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = loss_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(src[:,i].to(device), trg[:,i].to(device))\n",
    "output = model(src[:,i].to(device), trg[:,i].to(device), src_mask, tgt_mask,src_padding_mask, tgt_padding_mask, src_padding_mask)\n",
    "optimizer.zero_grad()\n",
    "loss = criterion(output.view(-1, output.shape[-1]), trg[:,i].to(device).view(-1))\n",
    "loss.backward()\n",
    "#torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No model loaded, starting training from scratch.\n",
      "Start training 0\n",
      "Validating... 0\n",
      "Epoch: 01 | Time: 3m 32s\n",
      "\tTrain Loss: 36.546 | Train PPL: 7446251130531807.000\n",
      "\t Val. Loss: 0.062 |    Val. PPL:   1.064\n",
      "Testing:\n",
      "\n",
      "\t Query:\n",
      "\tSOS a child is getting ready to read a book . EOS PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD\n",
      "\n",
      "\t Answer:\n",
      "\tSOS ein kleines mädchen , während eine frau , während eine frau , während eine frau , während eine frau , während eine frau , während eine frau , während eine frau , während eine frau , während ein mann\n",
      "\n",
      "\n",
      "\n",
      "Start training 1\n",
      "Validating... 1\n",
      "Epoch: 02 | Time: 3m 44s\n",
      "\tTrain Loss: 25.339 | Train PPL: 101103508198.335\n",
      "\t Val. Loss: 0.051 |    Val. PPL:   1.052\n",
      "Start training 2\n",
      "Validating... 2\n",
      "Epoch: 03 | Time: 3m 49s\n",
      "\tTrain Loss: 21.095 | Train PPL: 1450105604.061\n",
      "\t Val. Loss: 0.046 |    Val. PPL:   1.047\n",
      "Start training 3\n",
      "Validating... 3\n",
      "Epoch: 04 | Time: 3m 47s\n",
      "\tTrain Loss: 18.325 | Train PPL: 90883011.436\n",
      "\t Val. Loss: 0.041 |    Val. PPL:   1.042\n",
      "Start training 4\n",
      "Validating... 4\n",
      "Epoch: 05 | Time: 3m 44s\n",
      "\tTrain Loss: 16.313 | Train PPL: 12151654.360\n",
      "\t Val. Loss: 0.038 |    Val. PPL:   1.039\n",
      "Start training 5\n",
      "Validating... 5\n",
      "Epoch: 06 | Time: 3m 43s\n",
      "\tTrain Loss: 14.689 | Train PPL: 2396438.024\n",
      "\t Val. Loss: 0.037 |    Val. PPL:   1.038\n",
      "Start training 6\n",
      "Validating... 6\n",
      "Epoch: 07 | Time: 3m 41s\n",
      "\tTrain Loss: 13.364 | Train PPL: 636493.980\n",
      "\t Val. Loss: 0.036 |    Val. PPL:   1.036\n",
      "Start training 7\n",
      "Validating... 7\n",
      "Epoch: 08 | Time: 3m 42s\n",
      "\tTrain Loss: 12.269 | Train PPL: 213045.029\n",
      "\t Val. Loss: 0.035 |    Val. PPL:   1.035\n",
      "Start training 8\n",
      "Validating... 8\n",
      "Epoch: 09 | Time: 3m 45s\n",
      "\tTrain Loss: 11.304 | Train PPL: 81148.816\n",
      "\t Val. Loss: 0.035 |    Val. PPL:   1.036\n",
      "Start training 9\n",
      "Validating... 9\n",
      "Epoch: 10 | Time: 3m 47s\n",
      "\tTrain Loss: 10.477 | Train PPL: 35491.119\n",
      "\t Val. Loss: 0.034 |    Val. PPL:   1.035\n",
      "Start training 10\n",
      "Validating... 10\n",
      "Epoch: 11 | Time: 3m 44s\n",
      "\tTrain Loss: 9.741 | Train PPL: 17008.689\n",
      "\t Val. Loss: 0.035 |    Val. PPL:   1.035\n",
      "Testing:\n",
      "\n",
      "\t Query:\n",
      "\tSOS a policeman stopping a vehicle on the side of the road . EOS PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD\n",
      "\n",
      "\t Answer:\n",
      "\tSOS ein polizist holt an der seite eines autos aus der straße aus einer straße aus , der sich unter einer kirche durch eine kirche unter etwas aussieht . EOS\n",
      "\n",
      "\n",
      "\n",
      "Start training 11\n",
      "Validating... 11\n",
      "Epoch: 12 | Time: 3m 45s\n",
      "\tTrain Loss: 9.055 | Train PPL: 8563.335\n",
      "\t Val. Loss: 0.035 |    Val. PPL:   1.035\n",
      "Start training 12\n",
      "Validating... 12\n",
      "Epoch: 13 | Time: 3m 47s\n",
      "\tTrain Loss: 8.447 | Train PPL: 4660.544\n",
      "\t Val. Loss: 0.035 |    Val. PPL:   1.036\n",
      "Start training 13\n",
      "Validating... 13\n",
      "Epoch: 14 | Time: 3m 47s\n",
      "\tTrain Loss: 7.911 | Train PPL: 2726.083\n",
      "\t Val. Loss: 0.035 |    Val. PPL:   1.035\n",
      "Start training 14\n",
      "Validating... 14\n",
      "Epoch: 15 | Time: 3m 46s\n",
      "\tTrain Loss: 7.388 | Train PPL: 1617.020\n",
      "\t Val. Loss: 0.035 |    Val. PPL:   1.036\n",
      "Start training 15\n",
      "Validating... 15\n",
      "Epoch: 16 | Time: 4m 8s\n",
      "\tTrain Loss: 6.913 | Train PPL: 1005.652\n",
      "\t Val. Loss: 0.035 |    Val. PPL:   1.036\n",
      "Start training 16\n",
      "Validating... 16\n",
      "Epoch: 17 | Time: 4m 20s\n",
      "\tTrain Loss: 6.467 | Train PPL: 643.336\n",
      "\t Val. Loss: 0.035 |    Val. PPL:   1.036\n",
      "Start training 17\n",
      "Validating... 17\n",
      "Epoch: 18 | Time: 4m 53s\n",
      "\tTrain Loss: 6.047 | Train PPL: 422.995\n",
      "\t Val. Loss: 0.035 |    Val. PPL:   1.036\n",
      "Start training 18\n",
      "Validating... 18\n",
      "Epoch: 19 | Time: 4m 39s\n",
      "\tTrain Loss: 5.666 | Train PPL: 288.932\n",
      "\t Val. Loss: 0.035 |    Val. PPL:   1.035\n",
      "Start training 19\n",
      "Validating... 19\n",
      "Epoch: 20 | Time: 4m 35s\n",
      "\tTrain Loss: 5.326 | Train PPL: 205.594\n",
      "\t Val. Loss: 0.035 |    Val. PPL:   1.035\n",
      "Start training 20\n",
      "Validating... 20\n",
      "Epoch: 21 | Time: 4m 24s\n",
      "\tTrain Loss: 4.986 | Train PPL: 146.383\n",
      "\t Val. Loss: 0.035 |    Val. PPL:   1.035\n",
      "Testing:\n",
      "\n",
      "\t Query:\n",
      "\tSOS a blond boy in a blue t - shirt stands smiling before a craft of green nylon fabric . EOS PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD\n",
      "\n",
      "\t Answer:\n",
      "\tSOS ein blonder junge in einem blauen t-shirt steht lächelnd vor einem grüner teppich auf etwas , das sich in verschiedenen goldtönen durch seine zähnen hat , durch eine trinkt . EOS\n",
      "\n",
      "\n",
      "\n",
      "Start training 21\n",
      "Validating... 21\n",
      "Epoch: 22 | Time: 4m 22s\n",
      "\tTrain Loss: 4.667 | Train PPL: 106.376\n",
      "\t Val. Loss: 0.035 |    Val. PPL:   1.035\n",
      "Start training 22\n",
      "Validating... 22\n",
      "Epoch: 23 | Time: 4m 25s\n",
      "\tTrain Loss: 4.377 | Train PPL:  79.613\n",
      "\t Val. Loss: 0.035 |    Val. PPL:   1.036\n",
      "Start training 23\n",
      "Validating... 23\n",
      "Epoch: 24 | Time: 4m 26s\n",
      "\tTrain Loss: 4.096 | Train PPL:  60.108\n",
      "\t Val. Loss: 0.035 |    Val. PPL:   1.036\n",
      "Start training 24\n",
      "Validating... 24\n",
      "Epoch: 25 | Time: 4m 23s\n",
      "\tTrain Loss: 3.830 | Train PPL:  46.080\n",
      "\t Val. Loss: 0.037 |    Val. PPL:   1.038\n",
      "Start training 25\n",
      "Validating... 25\n",
      "Epoch: 26 | Time: 4m 24s\n",
      "\tTrain Loss: 3.581 | Train PPL:  35.895\n",
      "\t Val. Loss: 0.037 |    Val. PPL:   1.038\n",
      "Start training 26\n",
      "Validating... 26\n",
      "Epoch: 27 | Time: 5m 2s\n",
      "\tTrain Loss: 3.340 | Train PPL:  28.220\n",
      "\t Val. Loss: 0.037 |    Val. PPL:   1.038\n",
      "Start training 27\n",
      "Validating... 27\n",
      "Epoch: 28 | Time: 4m 36s\n",
      "\tTrain Loss: 3.100 | Train PPL:  22.199\n",
      "\t Val. Loss: 0.037 |    Val. PPL:   1.038\n",
      "Start training 28\n",
      "Validating... 28\n",
      "Epoch: 29 | Time: 4m 44s\n",
      "\tTrain Loss: 2.896 | Train PPL:  18.093\n",
      "\t Val. Loss: 0.037 |    Val. PPL:   1.038\n",
      "Start training 29\n",
      "Validating... 29\n",
      "Epoch: 30 | Time: 4m 46s\n",
      "\tTrain Loss: 2.703 | Train PPL:  14.928\n",
      "\t Val. Loss: 0.038 |    Val. PPL:   1.039\n",
      "Start training 30\n",
      "Validating... 30\n",
      "Epoch: 31 | Time: 4m 39s\n",
      "\tTrain Loss: 2.507 | Train PPL:  12.272\n",
      "\t Val. Loss: 0.037 |    Val. PPL:   1.038\n",
      "Testing:\n",
      "\n",
      "\t Query:\n",
      "\tSOS a red plane flying over a boat as it trails pink smoke . EOS PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD\n",
      "\n",
      "\t Answer:\n",
      "\tSOS ein rotes flugzeug fliegt über eine boot , als die südafrika aus als ob sich die zähne unter einer unter der aufschrift einer trinkt , die sich eine unter einer zähnen erschaffen hat . EOS\n",
      "\n",
      "\n",
      "\n",
      "Start training 31\n",
      "Validating... 31\n",
      "Epoch: 32 | Time: 4m 41s\n",
      "\tTrain Loss: 2.342 | Train PPL:  10.398\n",
      "\t Val. Loss: 0.037 |    Val. PPL:   1.037\n",
      "Start training 32\n",
      "Validating... 32\n",
      "Epoch: 33 | Time: 4m 40s\n",
      "\tTrain Loss: 2.195 | Train PPL:   8.976\n",
      "\t Val. Loss: 0.037 |    Val. PPL:   1.038\n",
      "Start training 33\n",
      "Validating... 33\n",
      "Epoch: 34 | Time: 4m 38s\n",
      "\tTrain Loss: 2.046 | Train PPL:   7.740\n",
      "\t Val. Loss: 0.037 |    Val. PPL:   1.038\n",
      "Start training 34\n",
      "Validating... 34\n",
      "Epoch: 35 | Time: 4m 42s\n",
      "\tTrain Loss: 1.909 | Train PPL:   6.747\n",
      "\t Val. Loss: 0.038 |    Val. PPL:   1.039\n",
      "Start training 35\n",
      "Validating... 35\n",
      "Epoch: 36 | Time: 4m 44s\n",
      "\tTrain Loss: 1.773 | Train PPL:   5.886\n",
      "\t Val. Loss: 0.038 |    Val. PPL:   1.039\n",
      "Start training 36\n",
      "Validating... 36\n",
      "Epoch: 37 | Time: 4m 44s\n",
      "\tTrain Loss: 1.658 | Train PPL:   5.249\n",
      "\t Val. Loss: 0.039 |    Val. PPL:   1.040\n",
      "Start training 37\n",
      "Validating... 37\n",
      "Epoch: 38 | Time: 4m 40s\n",
      "\tTrain Loss: 1.564 | Train PPL:   4.779\n",
      "\t Val. Loss: 0.039 |    Val. PPL:   1.040\n",
      "Start training 38\n",
      "Validating... 38\n",
      "Epoch: 39 | Time: 4m 44s\n",
      "\tTrain Loss: 1.460 | Train PPL:   4.308\n",
      "\t Val. Loss: 0.040 |    Val. PPL:   1.041\n",
      "Start training 39\n",
      "Validating... 39\n",
      "Epoch: 40 | Time: 4m 20s\n",
      "\tTrain Loss: 1.358 | Train PPL:   3.886\n",
      "\t Val. Loss: 0.041 |    Val. PPL:   1.041\n",
      "Start training 40\n",
      "Validating... 40\n",
      "Epoch: 41 | Time: 4m 17s\n",
      "\tTrain Loss: 1.286 | Train PPL:   3.617\n",
      "\t Val. Loss: 0.040 |    Val. PPL:   1.041\n",
      "Testing:\n",
      "\n",
      "\t Query:\n",
      "\tSOS many of the chairs are empty with only a few people enjoying the sun . EOS PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD\n",
      "\n",
      "\t Answer:\n",
      "\tSOS viele von oben auf leeren stühlen , die nur die sonne unter einer großen blauen wand unter der sich die waren durch die verlässt fünf unter einer verlässt und die lächelt . EOS\n",
      "\n",
      "\n",
      "\n",
      "Start training 41\n",
      "Validating... 41\n",
      "Epoch: 42 | Time: 4m 15s\n",
      "\tTrain Loss: 1.206 | Train PPL:   3.340\n",
      "\t Val. Loss: 0.040 |    Val. PPL:   1.041\n",
      "Start training 42\n",
      "Validating... 42\n",
      "Epoch: 43 | Time: 4m 20s\n",
      "\tTrain Loss: 1.135 | Train PPL:   3.110\n",
      "\t Val. Loss: 0.041 |    Val. PPL:   1.041\n",
      "Start training 43\n",
      "Validating... 43\n",
      "Epoch: 44 | Time: 4m 16s\n",
      "\tTrain Loss: 1.056 | Train PPL:   2.874\n",
      "\t Val. Loss: 0.041 |    Val. PPL:   1.042\n",
      "Start training 44\n",
      "Validating... 44\n",
      "Epoch: 45 | Time: 4m 17s\n",
      "\tTrain Loss: 1.003 | Train PPL:   2.726\n",
      "\t Val. Loss: 0.042 |    Val. PPL:   1.042\n",
      "Start training 45\n",
      "Validating... 45\n",
      "Epoch: 46 | Time: 4m 17s\n",
      "\tTrain Loss: 0.956 | Train PPL:   2.600\n",
      "\t Val. Loss: 0.042 |    Val. PPL:   1.042\n",
      "Start training 46\n",
      "Validating... 46\n",
      "Epoch: 47 | Time: 4m 17s\n",
      "\tTrain Loss: 0.900 | Train PPL:   2.460\n",
      "\t Val. Loss: 0.042 |    Val. PPL:   1.043\n",
      "Start training 47\n",
      "Validating... 47\n",
      "Epoch: 48 | Time: 4m 14s\n",
      "\tTrain Loss: 0.847 | Train PPL:   2.333\n",
      "\t Val. Loss: 0.044 |    Val. PPL:   1.045\n",
      "Start training 48\n",
      "Validating... 48\n",
      "Epoch: 49 | Time: 4m 17s\n",
      "\tTrain Loss: 0.817 | Train PPL:   2.264\n",
      "\t Val. Loss: 0.043 |    Val. PPL:   1.044\n",
      "Start training 49\n",
      "Validating... 49\n",
      "Epoch: 50 | Time: 4m 19s\n",
      "\tTrain Loss: 0.786 | Train PPL:   2.195\n",
      "\t Val. Loss: 0.042 |    Val. PPL:   1.043\n",
      "Start training 50\n",
      "Validating... 50\n",
      "Epoch: 51 | Time: 4m 20s\n",
      "\tTrain Loss: 0.734 | Train PPL:   2.083\n",
      "\t Val. Loss: 0.042 |    Val. PPL:   1.043\n",
      "Testing:\n",
      "\n",
      "\t Query:\n",
      "\tSOS a man in a cluttered office is using the telephone EOS PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD\n",
      "\n",
      "\t Answer:\n",
      "\tSOS ein mann in einem überladenen büro benutzt die aufschrift „ grüner arbeit “ und hat sich nicht in einer heilquelle im freien vor , die sich einer gegen die sich etwas vor hat , die sich etwas vor hat\n",
      "\n",
      "\n",
      "\n",
      "Start training 51\n",
      "Validating... 51\n",
      "Epoch: 52 | Time: 4m 15s\n",
      "\tTrain Loss: 0.702 | Train PPL:   2.018\n",
      "\t Val. Loss: 0.044 |    Val. PPL:   1.045\n",
      "Start training 52\n",
      "Validating... 52\n",
      "Epoch: 53 | Time: 4m 17s\n",
      "\tTrain Loss: 0.672 | Train PPL:   1.958\n",
      "\t Val. Loss: 0.042 |    Val. PPL:   1.043\n",
      "Start training 53\n",
      "Validating... 53\n",
      "Epoch: 54 | Time: 4m 15s\n",
      "\tTrain Loss: 0.639 | Train PPL:   1.895\n",
      "\t Val. Loss: 0.045 |    Val. PPL:   1.046\n",
      "Start training 54\n",
      "Validating... 54\n",
      "Epoch: 55 | Time: 4m 14s\n",
      "\tTrain Loss: 0.615 | Train PPL:   1.850\n",
      "\t Val. Loss: 0.045 |    Val. PPL:   1.046\n",
      "Start training 55\n",
      "Validating... 55\n",
      "Epoch: 56 | Time: 4m 13s\n",
      "\tTrain Loss: 0.603 | Train PPL:   1.827\n",
      "\t Val. Loss: 0.044 |    Val. PPL:   1.045\n",
      "Start training 56\n",
      "Validating... 56\n",
      "Epoch: 57 | Time: 4m 19s\n",
      "\tTrain Loss: 0.570 | Train PPL:   1.768\n",
      "\t Val. Loss: 0.043 |    Val. PPL:   1.044\n",
      "Start training 57\n",
      "Validating... 57\n",
      "Epoch: 58 | Time: 4m 16s\n",
      "\tTrain Loss: 0.551 | Train PPL:   1.735\n",
      "\t Val. Loss: 0.044 |    Val. PPL:   1.045\n",
      "Start training 58\n",
      "Validating... 58\n",
      "Epoch: 59 | Time: 4m 17s\n",
      "\tTrain Loss: 0.530 | Train PPL:   1.698\n",
      "\t Val. Loss: 0.043 |    Val. PPL:   1.044\n",
      "Start training 59\n",
      "Validating... 59\n",
      "Epoch: 60 | Time: 4m 14s\n",
      "\tTrain Loss: 0.509 | Train PPL:   1.663\n",
      "\t Val. Loss: 0.044 |    Val. PPL:   1.045\n",
      "Start training 60\n",
      "Validating... 60\n",
      "Epoch: 61 | Time: 4m 14s\n",
      "\tTrain Loss: 0.495 | Train PPL:   1.640\n",
      "\t Val. Loss: 0.044 |    Val. PPL:   1.045\n",
      "Testing:\n",
      "\n",
      "\t Query:\n",
      "\tSOS a man and woman fishing at the beach . EOS PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD\n",
      "\n",
      "\t Answer:\n",
      "\tSOS ein mann und eine frau fischen auf den strand , um die vor dem großen , wobei sich etwas zu hat , bei dem seine arbeit unter den nacktem oberkörper unterschiedlicher größe betrachtet , vor , was als ob\n",
      "\n",
      "\n",
      "\n",
      "Start training 61\n",
      "Validating... 61\n",
      "Epoch: 62 | Time: 4m 13s\n",
      "\tTrain Loss: 0.479 | Train PPL:   1.615\n",
      "\t Val. Loss: 0.044 |    Val. PPL:   1.045\n",
      "Start training 62\n",
      "Validating... 62\n",
      "Epoch: 63 | Time: 4m 14s\n",
      "\tTrain Loss: 0.460 | Train PPL:   1.585\n",
      "\t Val. Loss: 0.045 |    Val. PPL:   1.046\n",
      "Start training 63\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_13952/1380627217.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Start training'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m     \u001b[0mtrain_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_bert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Validating...'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[0mvalid_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mevaluate_bert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalsrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvaltrg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_13952/1880830683.py\u001b[0m in \u001b[0;36mtrain_bert\u001b[1;34m(model, optimizer, criterion, src, trg)\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[1;31m#torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m         \u001b[0mepoch_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m         \u001b[0mgc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\vormenesse\\anaconda3\\lib\\site-packages\\torch\\optim\\optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     86\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m                 \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 88\u001b[1;33m                     \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     89\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\vormenesse\\anaconda3\\lib\\site-packages\\torch\\autograd\\grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\vormenesse\\anaconda3\\lib\\site-packages\\torch\\optim\\adam.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    131\u001b[0m                     \u001b[0mstate_steps\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'step'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 133\u001b[1;33m             F.adam(params_with_grad,\n\u001b[0m\u001b[0;32m    134\u001b[0m                    \u001b[0mgrads\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    135\u001b[0m                    \u001b[0mexp_avgs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\vormenesse\\anaconda3\\lib\\site-packages\\torch\\optim\\_functional.py\u001b[0m in \u001b[0;36madam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps)\u001b[0m\n\u001b[0;32m     96\u001b[0m         \u001b[0mstep_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlr\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mbias_correction1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 98\u001b[1;33m         \u001b[0mparam\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maddcdiv_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexp_avg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdenom\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mstep_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 1000\n",
    "CLIP = 1\n",
    "path = './'\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "try: \n",
    "    model.load_state_dict(torch.load(path+'math-bert-model.pt'))\n",
    "    print('Model Loaded Successfully!')\n",
    "except:\n",
    "    print('No model loaded, starting training from scratch.')\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    start_time = time.time()\n",
    "    print('Start training',epoch)\n",
    "    train_loss = train_bert(model, optimizer, loss_fn, src, trg)\n",
    "    print('Validating...',epoch)\n",
    "    valid_loss = evaluate_bert(model, loss_fn, valsrc, valtrg)\n",
    "\n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), path+'math-bert-model.pt')\n",
    "\n",
    "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |    Val. PPL: {math.exp(valid_loss):7.3f}')\n",
    "    with open(path+\"modelTrainingOutput.txt\", \"a\") as textFile:\n",
    "        textFile.write(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s\\n')\n",
    "        textFile.write(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}\\n')\n",
    "        textFile.write(f'\\t Val. Loss: {valid_loss:.3f} |    Val. PPL: {math.exp(valid_loss):7.3f}\\n')\n",
    "    if epoch % 10 == 0:\n",
    "        with torch.no_grad():\n",
    "            rnd = np.random.randint(1,100)\n",
    "            o = greedy_decode(model, valsrc[:,rnd-1:rnd].to(device),40)\n",
    "            query = ' '.join( engVocabulary.index2word[i] for i in valsrc[:,rnd-1:rnd].squeeze().cpu().numpy())\n",
    "            answer = ' '.join( deVocabulary.index2word[i] for i in o.squeeze().cpu().numpy())\n",
    "        print(f'Testing:\\n')\n",
    "        print(f'\\t Query:\\n\\t'+query+'\\n')\n",
    "        print(f'\\t Answer:\\n\\t'+answer+'\\n')\n",
    "        print(f'\\n')\n",
    "        with open(path+\"modelTrainingOutput.txt\", \"a\") as textFile:\n",
    "            textFile.write(f'Testing:\\n')\n",
    "            textFile.write(f'\\t Query:\\n\\t'+query+'\\n')\n",
    "            textFile.write(f'\\t Answer:\\n\\t'+answer+'\\n')\n",
    "            textFile.write(f'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "shape '[40, 1]' is invalid for input of size 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_6380/1560682007.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mgreedy_decode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalsrc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrnd\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mrnd\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m40\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_6380/213261907.py\u001b[0m in \u001b[0;36mgreedy_decode\u001b[1;34m(model, src, max_len, start_symbol)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mgreedy_decode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_len\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstart_symbol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;31m#print(src.shape)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0msrc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax_len\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[1;31m#print(src.shape)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mnum_tokens\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: shape '[40, 1]' is invalid for input of size 0"
     ]
    }
   ],
   "source": [
    "greedy_decode(model, valsrc[:,rnd-1:rnd].to(device),40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
